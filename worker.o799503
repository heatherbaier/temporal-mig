Warning: no access to tty (Bad file descriptor).
Thus no job control in this shell.
128.239.59.1
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 578, in __init__
    dist._verify_model_across_ranks(self.process_group, parameters)
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.5]:53128
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:31377
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:24752
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:35467
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:57520
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:63917
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:62123
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 122, in main
    output = ddp_model(input)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1379, in _sync_params
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:11942
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:50309
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 122, in main
    output = ddp_model(input)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1379, in _sync_params
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
        dist._broadcast_coalesced(main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)

RuntimeError  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:64155
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:11680
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 122, in main
    output = ddp_model(input)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1379, in _sync_params
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:26545
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:7607
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:37302
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 122, in main
    output = ddp_model(input)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1379, in _sync_params
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
        dist._broadcast_coalesced(main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)

RuntimeError:   File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
[/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:43409
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:40333
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 122, in main
    output = ddp_model(input)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1379, in _sync_params
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:54683
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:17035
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:36275
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
    ddp_model = DDP(model, process_group = model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 580, in __init__
    self._sync_params_and_buffers(authoritative_rank=0)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 597, in _sync_params_and_buffers
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:25248
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/tm/run.py", line 242, in <module>
    main(int(os.environ["RANK"]), int(os.environ['WORLD_SIZE']), model_group)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/tm/run.py", line 122, in main
    output = ddp_model(input)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1379, in _sync_params
    self._distributed_broadcast_coalesced(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1334, in _distributed_broadcast_coalesced
    dist._broadcast_coalesced(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.1]:28289
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187534 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187535 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187536 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187537 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187538 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187539 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187540 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187541 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187542 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187544 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187545 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187546 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187547 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187548 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187549 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187550 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187551 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187552 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187553 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187554 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187555 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187556 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187558 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187559 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187560 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187561 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187562 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187563 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187564 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187566 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 187567 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 187533) of binary: /sciclone/home20/hmbaier/.conda/envs/dhsrl4/bin/python
ERROR:torch.distributed.elastic.agent.server.api:Error waiting on exit barrier. Elapsed: 3.6076385974884033 seconds
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 899, in _exit_barrier
    store_util.barrier(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/utils/store.py", line 67, in barrier
    synchronize(store, data, rank, world_size, key_prefix, barrier_timeout)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/utils/store.py", line 53, in synchronize
    agent_data = get_all(store, key_prefix, world_size)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/utils/store.py", line 31, in get_all
    data = store.get(f"{prefix}{idx}")
RuntimeError: Connection reset by peer
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'mlt003.sciclone.wm.edu_187530_0' has failed to send a keep-alive heartbeat to the rendezvous '790876' due to an error of type RendezvousConnectionError.
WARNING:torch.distributed.elastic.rendezvous.dynamic_rendezvous:The node 'mlt003.sciclone.wm.edu_187530_0' has failed to shutdown the rendezvous '790876' due to an error of type RendezvousConnectionError.
ERROR:torch.distributed.elastic.multiprocessing.errors.error_handler:no error file defined for parent, to copy child error file (/local/scr/hmbaier/TMPDIR/torchelastic_1pl4y_xh/790876_t4w9bzdk/attempt_0/0/error.json)
Traceback (most recent call last):
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==1.10.0', 'console_scripts', 'torchrun')())
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/run.py", line 719, in main
    run(args)
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/run.py", line 710, in run
    elastic_launch(
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/sciclone/home20/hmbaier/tm/run.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2022-03-10_15:54:46
  host      : mlt003.sciclone.wm.edu
  rank      : 64 (local_rank: 0)
  exitcode  : 1 (pid: 187533)
  error_file: /local/scr/hmbaier/TMPDIR/torchelastic_1pl4y_xh/790876_t4w9bzdk/attempt_0/0/error.json
  traceback : Traceback (most recent call last):
    File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
      return f(*args, **kwargs)
    File "/sciclone/home20/hmbaier/tm/run.py", line 100, in main
      ddp_model = DDP(model, process_group = model_group)
    File "/sciclone/home20/hmbaier/.conda/envs/dhsrl4/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 578, in __init__
      dist._verify_model_across_ranks(self.process_group, parameters)
  RuntimeError: [/opt/conda/conda-bld/pytorch_1634272107467/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [10.3.59.5]:53128
  
============================================================
